\chapter{The rise of HPC}

High Performance Computing (\textbf{HPC}) is an old topic in computer science: it has always allowed to perform powerful simulations and computations, which would be usually impossible in modern, domestic systems. We care a lot about simulations because they are the \textbf{Third Pillar of Science}: they allow humans to overcome the limits of experimental science (over dangerous limits, costs and time limitations), so since the rise of this field of CS, society has been needing coherent machines to overcome even greater limits.
\nwl
In time, there has been a shift in the kind of architecture used in HPC settings: since 2015 (when the Dennard Law broke) we stopped focusing about the max frequency of a processor; now we focus instead on other capabilities (such as the number and types of cores in a chip) or on novel architectures, because they harness different capabilities.
\nwl
Also the manufacturing process of these chips changed during time: nowadays chips in GPUs, CPUs and so on are made with \textbf{chiplets}, a manufacturing process for which different components are built by stacking layers of silicon together. The results are impressive: supercomputers from the Top500 (a list of the best supercomputers, started in 1993) can reach, jointly, up to 4.8 Eflop/s. A modern computer may reach the power of the most performant supercomputer from 1996!
\nwl
Back in the days, when the Top500 list was born, Intel was the predominant architecture, using the \verb|i860| architecture. Today, $78\%$ of the supercomputers use Intel with the \verb|x86-64| architecture ($97\%$ of the supercomputers use \verb|x86-64|). But shifts of architectures are not that frequent, and that is because a change costs too much, so the scientific community sticks with an architecture until the time when it becomes obsolete. However, nowadays we don't use anymore solely CPUs: GPUs (and in general, accelerators) are the dealbreaker.
\nwl
Curiously, at the time (during what is called the \textbf{first phase} of HPC) it was more convenient to use shared memory architecture, opposed to today, where distributed is the new standard. However things changed in 1994, when an experiment, the \textbf{Beowulf cluster}, was run: it consisted in multiple Linux machines running together in parallel in order to complete a joint task. This showed how multiple, singular machines could work way better than single, monolithic supercomputers. This marked the beginning of the \textbf{second phase} of HPC. Now we are in the \textbf{third phase}: we moved to \textbf{heterogeneous architectures}, using GPUs, and we are heading to the \textbf{fourth phase}, where \textbf{experimentation} and specialized architectures are investigated and used (consider TPUs, DPUs and special architectures such as Cerebras, Graphcore and Tenstorrent).
\nwl
Modern supercomputers have some commonalities: NVIDIA dominates in the accelerators field, interconnects use either Ethernet or InfiniBand (a technology made by NVIDIA; indeed, 426 out of 500 supercomputers from the modern Top500 use this kind of interconnect), and most of these computers (if not all of them!) use Linux as OS.
\nwl
Programs are not built in Python, but usually in fast, low-level languages (such as C) with the aid of libraries such as MPI, OpenMP and CUDA/HIP (for AMD's accelerators). Floating point operations also employ different precision standards (from 64 to 8 bits), and are used in different contexts and scenarios (while AI training doesn't need the highest precision available in a computer, simulating a bridge does).

\section{HPC systems' structure}

HPC systems have different components:
\begin{itemize}
    \item CPUs, which nowadays are all multicore CPUs;
    \item accelerators, such as general purpose GPUs;
    \item memory;
    \item storage systems;
    \item interconnects.
\end{itemize}

Novel architectures employ hardware such as TPUs, NPUs or FPGAs (Field Programmable Gated Arrays).
\nwl
Nodes is a system can be used for different tasks: for computation, for storage, for data processing, etc... And all nodes in a supercomputer are interconnected through some way. Interconnections can be inter-node, intra-rack (node to node connections) and inter-rack. 
\nwl
Inter-node communications happen within a compute node, between CPU, GPU, memory, etc... Technologies used vary depending on the node: we may use CPU-CPU interconnects, GPU-GPU links (such as the NVLink), or CPU-Accelerator (such as PCIe Gen 5/6, which are used also in domestic machines).
\nwl
Intra-rack interconnection happens within nodes in the same rack. Technologies used are for instance the InfiniBand from NVIDIA, the Slingshot, Ethernet or UltraEthernet.
\nwl
Inter-rack communication happens between racks. The main problem with this kind of connections is that we don't have enough bandwidth to connect all the racks together. The technologies used are the same of the intra-rack communication, but with some tweaks for allowing scalability (examples are Dragonfly, Fat-Tree, Torus, or HyperX). There has been some interest lately for optical interconnects. This kind of technologies allow for scalability, fault tolerance and congestion control.

\subsection{Study case: Leonardo (CINECA)}

Let us consider a very familiar supercomputer: Leonardo. Nodes are based on the Atos BullSequana XH2000 design, and nodes either designed for hosting a CPU partition or a booster partition with NVIDIA A100 GPUs. It uses Mellanox interconnects.
\nwl
There are some nodes used as front-end nodes (16), which are needed for interfacing with the supercomputer. The partitions are as follows:
\begin{itemize}
    \item \textbf{Data Centric} and \textbf{General Purpose partitions}, which are nodes with 3-nodes blades, where each node counts 2 CPUs;
    \item \textbf{Booster GPU partition}, also called "Da Vinci" blades, they are diskless and are intended to host 4 NVIDIA Ampere A100 GPUs.
\end{itemize}

The topology used to connect the nodes is called Dragonfly+, and is based on the NVIDIA Mellanox Infiniband, capable of transmitting up to 200 Gb/s.
\nwl
Now Leonardo is also being expanded with an other partition, called LISA, made specifically for AI purposes. In this partition, the GPUs (which use last generation accelerators, such as the NVIDIA H100 GPUs) are collected all together through an NVIDIA NVLink, so there is no CPU work involved in the communication.

\section{The performance of an HPC system}

Performances on HPC systems are usually measured by a benchmark which solves dense matrix linear systems (HPL benchmark). Another kind of benchmark (HPCG) is based on sparse matrices and conjugate gradient (hence the CG): with these kind of benchmarks, we have no more sequential access to data, rather a discontinuous one (due to the sparse matrices).
\nwl
The performances vary depending on the benchmarks: indeed, computers achieving peak performance in HPL might not have peak performance in HPCG (or may not keep the same position).
\nwl
Nowadays we also measure performance based on AI/ML benchmarks. While AI/ML have been around for a while, we've been only able to better tackle them now because of increasing data and computational power. This means that the support from researchers/industries towards the AI/ML scenery has deeply increased. The interesting part of AI/ML tasks is that we have simple operations that are repeated many times on different data.
\nwl
Also, we are shifting from higher-precision formats to smaller ones (for instance, from 32 to 16). Interestingly, other precision format have been developed, such as the Google Bfloat format (B standing for Brain), which uses a different amount of bits for explaining exponents and mantissa. In this case, Bfloat can represent a greater range at the cost of a lower precision. Moving from IEEE to Bfloat has no cost whatsoever.

\section{High performance programming}

When we measure a HPC system, we use the $x$flop/s measurement (where $x$ is kilo, mega, giga, etc...), which denoted how many 64-bits floating-point operations (either addition or multiplication) are done in a second by a system. The theoretical peak performance of a system is given by the theoretical amount of flop/s that a system can compute over a specific time range.
\nwl
An interesting example: an Intel Skylake processor has 2.1 GHz per core, and can do 32 flops per cycle, per core. But how can it achieve that? This is because there are some instructions that work on vectorized data. Such instructions are the SIMD (Single Instruction Multiple Data) instructions, which work on multiple data together.
\nwl
As an example of how fast these operations can be: let us consider a na√Øve implementation in Python of a DGEMM operation between two $\mathbb{R}^{4K \times 4K}$ matrices as the baseline; if we consider a C program, with the same algorithm, we can have a speedup of $47\times$. If we use vectorized operations, we can reach a speedup of $23.000\times$, but if we use instead intrinsic Assembly operations (AVX intrinsic), we can have up to $62.000 \times$ speedup.
\nwl
How can we improve a single-node application though? There are many ways to do so, but in order to identify the best course of action we should:
\begin{itemize}
    \item [1)] measure the performance of the application;
    \item [2)] understand the hardware of the machine running the program;
    \item [3)] identify any possible bottleneck (check if the problem is memory bound, compute bound or related to under-utilization of the machine's resources);
    \item [4)] solve the bottlenecks, if possible;
    \item [5)] repeat until you are satisfied with your performance.
\end{itemize}

Usually, some good pieces of advice are the following:
\begin{itemize}
    \item [1)] optimize the algorithms used and the data structures (aka use quick sort and hash tables), but don't be greedy: some algorithms might perform better than others only in some specific situations. An example is quick sort vs counting sort: while counting sort is fast, it only holds for limited ranges of values. Choose the best algorithm depending on your problem;
    \item [2)] perform memory optimizations: most applications usually suffer from memory bottlenecks, mostly because of the moving of the data. It's important to carefully use caching and avoid cache misses. The idea is to have a balance between flops and data transfer rate (hence balancing the $\text{flop}/s$ and the $\text{loaded word}/s$). Reaching the balance of $\nicefrac{1}{1}$ is nearly impossible, but we should strive to reach it;
    \item [3)] exploit hardware parallelism: don't have unutilized resources if you can avoid it. There are two types of parallelism that we can achieve: data parallelism (same task on different data) and thread parallelism (use different threads to execute an algorithm. Might give false sharing issues).
\end{itemize}